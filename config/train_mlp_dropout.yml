data:
  augmentation: null
  batch_size: 128
  dataset: MNIST
logger:
  entity: your_wandb_entity
  project: pytorch-lightning-uv
  run_name: test_MLP_Dropout_batchnorm
model:
  activation: relu
  dropout: 0.2
  n_layer_1: 512
  n_layer_2: 128
  name: MLP
optimizer:
  lr: 0.0001
  name: adam
training:
  accumulate_grad_batches: null
  gradient_clip_val: null
  max_epochs: 25
  precision: null
